{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78b8d782d9be407382d0cebc8b9e92bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f22f4bcb5424253aae45a9dfb10d7b1",
              "IPY_MODEL_d1cef0c240c142edba7792e49140b854",
              "IPY_MODEL_68767fae52f042c6884628e4585a0e01"
            ],
            "layout": "IPY_MODEL_3cb53a26e4e7415aae70728e4314e890"
          }
        },
        "1f22f4bcb5424253aae45a9dfb10d7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3071ed21ba2a40a5b81280efb95e6438",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_42806e25f90d4d90ac1803e51d6a2dc7",
            "value": "‚Äá‚Äá0%"
          }
        },
        "d1cef0c240c142edba7792e49140b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc04fa63b364128b635d08fb109f771",
            "max": 11250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b228871c6b84d17922978c9aeb0607e",
            "value": 0
          }
        },
        "68767fae52f042c6884628e4585a0e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b41e388a434ef89a9f1f765e3ef735",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_427b071df41b44ca9d6b055e66816cd2",
            "value": "‚Äá0/11250‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "3cb53a26e4e7415aae70728e4314e890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3071ed21ba2a40a5b81280efb95e6438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42806e25f90d4d90ac1803e51d6a2dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc04fa63b364128b635d08fb109f771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b228871c6b84d17922978c9aeb0607e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b41e388a434ef89a9f1f765e3ef735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427b071df41b44ca9d6b055e66816cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c1aA-BKRAgZ",
        "outputId": "13e5e7dc-5c34-450c-e6df-d67aca0ae067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#SAVE_PATH = \"/content/drive/MyDrive/imdb-bert2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "!pip install transformers datasets scikit-learn pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIrufeIORIL_",
        "outputId": "db886741-a926-4038-a9df-6ec1228b9744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGtOxGB3Rdth",
        "outputId": "788a4b4b-7ea8-4e3b-d1b2-3ab2d794a40f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load Dataset\n",
        "df = pd.read_csv(\"agri_classification_dataset.csv\")\n",
        "#df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n"
      ],
      "metadata": {
        "id": "W8Lar47wRgJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'].tolist(), df['label'].tolist(), test_size=0.1, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "lA3AxIsKRi2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "s1AUqd9LR0N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Tokenize (save if not already saved)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
        "torch.save(train_encodings, f\"{SAVE_PATH}/train_encodings.pt\")\n",
        "torch.save(val_encodings, f\"{SAVE_PATH}/val_encodings.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AHzyO_ReRlRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Dataset Class\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
        "val_dataset = IMDBDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "CnyVCCLaR4ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Model & Training Setup\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylvKuGe_SB0f",
        "outputId": "06b0aca9-2cf4-47d7-da70-bc13660e59f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from transformers import get_scheduler\n",
        "\n",
        "\n",
        "\n",
        "# ‚úÖ Add Scheduler\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=100,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# ‚úÖ Training loop with scheduler\n",
        "for epoch in range(num_epochs):\n",
        "    try:\n",
        "        model.train()\n",
        "        print(f\"üîÅ Epoch {epoch + 1}/{num_epochs}\")\n",
        "        loop = tqdm(train_loader)\n",
        "        for batch in loop:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()  # ‚úÖ Step the scheduler\n",
        "            loop.set_description(f\"Epoch {epoch + 1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # ‚úÖ Save after each epoch\n",
        "        model.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}\")\n",
        "        tokenizer.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}\")\n",
        "        print(f\"‚úÖ Model saved after epoch {epoch+1}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error occurred, saving current checkpoint...\")\n",
        "        model.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}-crash\")\n",
        "        tokenizer.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}-crash\")\n",
        "        raise e\n",
        "\n",
        "# ‚úÖ Evaluation after training\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"üîç Evaluating\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, axis=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"\\nüìä Classification Report on Validation Set:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Non-agriculture\", \"Agriculture\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "78b8d782d9be407382d0cebc8b9e92bc",
            "1f22f4bcb5424253aae45a9dfb10d7b1",
            "d1cef0c240c142edba7792e49140b854",
            "68767fae52f042c6884628e4585a0e01",
            "3cb53a26e4e7415aae70728e4314e890",
            "3071ed21ba2a40a5b81280efb95e6438",
            "42806e25f90d4d90ac1803e51d6a2dc7",
            "3bc04fa63b364128b635d08fb109f771",
            "0b228871c6b84d17922978c9aeb0607e",
            "c1b41e388a434ef89a9f1f765e3ef735",
            "427b071df41b44ca9d6b055e66816cd2"
          ]
        },
        "id": "hlcQwiqySFWh",
        "outputId": "2a919796-91a0-498a-e9cf-989e939088f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÅ Epoch 1/5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b8d782d9be407382d0cebc8b9e92bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Change this to your desired checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/imdb-bert1/checkpoint-epoch3-fine-tuned-fine-tuned\"\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint_path)\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIfuRrZYSJcE",
        "outputId": "9d98c035-0307-4c4e-a385-9d5dd6e27c93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        label = \"Agriculture\" if pred == 1 else \"Non-agriculture\"\n",
        "        confidence = probs[0][pred].item()\n",
        "\n",
        "    return label, confidence\n"
      ],
      "metadata": {
        "id": "1B6fsgyMnLnS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    \"My wheat crops are drying up even though the soil is moist‚Äîcould it be a fungus or something else?\",\n",
        "    \"The recent Bollywood film touched upon farmer suicides, quite a heavy topic.\",\n",
        "    \"How do I switch from chemical to organic farming without losing my yield?\",\n",
        "    \"Do you know the actor who played the farmer in that Marathi biopic?\",\n",
        "    \"Water stress in maize during tasseling stage is affecting cob formation‚Äîany recommendations?\",\n",
        "    \"Just watched a documentary on climate change and its effects on agriculture in the Himalayan belt.\",\n",
        "    \"I heard neem-based pesticides are good, but I don‚Äôt know the dilution ratio for chili crops.\",\n",
        "    \"Can excessive rainfall delay flowering in pulses like urad and moong?\",\n",
        "    \"My neighbors used some new fertigation technique; is that viable for sugarcane in clay soil?\",\n",
        "    \"The storyline was confusing, but the cinematography in the paddy fields looked stunning!\",\n",
        "    ]\n",
        "\n",
        "for text in examples:\n",
        "    label, conf = predict_sentiment(text)\n",
        "    print(f\"üìù Review: {text}\\nüîé Prediction: {label} ({conf*100:.2f}% confidence)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XwtmI9dnRxQ",
        "outputId": "8e5da42c-84c3-4da3-ad4a-64ccb90cc23b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Review: My wheat crops are drying up even though the soil is moist‚Äîcould it be a fungus or something else?\n",
            "üîé Prediction: Agriculture (98.36% confidence)\n",
            "\n",
            "üìù Review: The recent Bollywood film touched upon farmer suicides, quite a heavy topic.\n",
            "üîé Prediction: Non-agriculture (99.78% confidence)\n",
            "\n",
            "üìù Review: How do I switch from chemical to organic farming without losing my yield?\n",
            "üîé Prediction: Agriculture (98.80% confidence)\n",
            "\n",
            "üìù Review: Do you know the actor who played the farmer in that Marathi biopic?\n",
            "üîé Prediction: Non-agriculture (95.95% confidence)\n",
            "\n",
            "üìù Review: Water stress in maize during tasseling stage is affecting cob formation‚Äîany recommendations?\n",
            "üîé Prediction: Agriculture (99.69% confidence)\n",
            "\n",
            "üìù Review: Just watched a documentary on climate change and its effects on agriculture in the Himalayan belt.\n",
            "üîé Prediction: Non-agriculture (91.25% confidence)\n",
            "\n",
            "üìù Review: I heard neem-based pesticides are good, but I don‚Äôt know the dilution ratio for chili crops.\n",
            "üîé Prediction: Agriculture (99.46% confidence)\n",
            "\n",
            "üìù Review: Can excessive rainfall delay flowering in pulses like urad and moong?\n",
            "üîé Prediction: Agriculture (99.62% confidence)\n",
            "\n",
            "üìù Review: My neighbors used some new fertigation technique; is that viable for sugarcane in clay soil?\n",
            "üîé Prediction: Agriculture (99.35% confidence)\n",
            "\n",
            "üìù Review: The storyline was confusing, but the cinematography in the paddy fields looked stunning!\n",
            "üîé Prediction: Non-agriculture (99.92% confidence)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment( \"My wheat crops are drying up even though the soil is moist‚Äîcould it be a fungus or something else?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtcdV7tMcxyZ",
        "outputId": "68c28077-c38f-4a05-9ba5-92a4a2ba5283"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Agriculture', 0.9883082509040833)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-_sPM5RVYb_",
        "outputId": "ceeaa401-87eb-4677-9dfc-ae456074fff3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3  Unnamed: 4     Unnamed: 5  \\\n",
            "0         NaN       Year      Month        Day       State       District   \n",
            "1         NaN       2025       June         23  Tamil Nadu  Ramanthapuram   \n",
            "2         NaN       2025       June         23  Tamil Nadu  Ramanthapuram   \n",
            "\n",
            "    Unnamed: 6 Unnamed: 7 Unnamed: 8  Unnamed: 9  \\\n",
            "0       Sector     Season       Crop  Sl No. - Q   \n",
            "1  Agriculture     Kharif     Chilli          Q1   \n",
            "2  Agriculture     Kharif     Chilli          Q2   \n",
            "\n",
            "                                         Unnamed: 10 Unnamed: 11  \\\n",
            "0                                           Question  Sl No. - A   \n",
            "1  How much FYM-Farm yard manure should I add to ...          A1   \n",
            "2  What are the market opportunities I have if I ...          A2   \n",
            "\n",
            "                                         Unnamed: 12  \n",
            "0                                             Answer  \n",
            "1  Apply 8‚Äì10 tons per acre of well-decomposed FY...  \n",
            "2  Chillies have market opportunities in food pro...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm  # ‚úÖ Import tqdm\n",
        "\n",
        "# üîΩ Load your CSV file\n",
        "df = pd.read_csv(\"twitter_dataset.csv\")  # Replace with actual file path\n",
        "\n",
        "# üîΩ Run prediction on the 'Text' column\n",
        "agri_count = 0\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "# ‚úÖ tqdm for progress bar\n",
        "for question in tqdm(df['Text'], desc=\"üîç Predicting\", unit=\"question\"):\n",
        "    label, conf = predict_sentiment(question)\n",
        "    predictions.append(label)\n",
        "    confidences.append(conf)\n",
        "    if label == \"Agriculture\":\n",
        "        agri_count += 1\n",
        "\n",
        "# üîΩ Add to DataFrame\n",
        "df['predicted_label'] = predictions\n",
        "df['confidence'] = confidences\n",
        "\n",
        "# üîΩ Print the count\n",
        "print(f\"üåæ Total Agriculture-related questions: {agri_count} out of {len(df)}\")\n",
        "\n",
        "# üîΩ Save results\n",
        "df.to_csv(\"questions_with_predictions.csv\", index=False)\n",
        "print(\"‚úÖ Saved predictions to questions_with_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HAuUss5Uyub",
        "outputId": "d05f656d-43cd-46cb-eb2d-7642afdd3706"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [01:51<00:00, 89.40question/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåæ Total Agriculture-related questions: 0 out of 10000\n",
            "‚úÖ Saved predictions to questions_with_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm  # ‚úÖ Import tqdm\n",
        "\n",
        "# üîΩ Load your CSV file\n",
        "df = pd.read_csv(\"Copy of Tamilnadu Crops by Ponugoti Kavya_Chilli-Tamil Nadu.csv\")  # Replace with actual file path\n",
        "\n",
        "# üîΩ Run prediction on the 'Text' column\n",
        "agri_count = 0\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "# ‚úÖ tqdm for progress bar\n",
        "for question in tqdm(df['Unnamed: 10'], desc=\"üîç Predicting\", unit=\"question\"):\n",
        "    label, conf = predict_sentiment(question)\n",
        "    predictions.append(label)\n",
        "    confidences.append(conf)\n",
        "    if label == \"Agriculture\":\n",
        "        agri_count += 1\n",
        "\n",
        "# üîΩ Add to DataFrame\n",
        "df['predicted_label'] = predictions\n",
        "df['confidence'] = confidences\n",
        "\n",
        "# üîΩ Print the count\n",
        "print(f\"üåæ Total Agriculture-related questions: {agri_count} out of {len(df)}\")\n",
        "\n",
        "# üîΩ Save results\n",
        "df.to_csv(\"questions_with_predictions.csv\", index=False)\n",
        "print(\"‚úÖ Saved predictions to questions_with_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rPG07Y117N1",
        "outputId": "f04199cf-47e8-4c9b-fe9d-c64ef6831a6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 202/202 [00:02<00:00, 100.58question/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåæ Total Agriculture-related questions: 202 out of 202\n",
            "‚úÖ Saved predictions to questions_with_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agri_df = df[df['predicted_label'] == \"Agriculture\"]\n",
        "agri_df['label'] = 0\n",
        "agri_df[['Text', 'label']].to_csv(\"fine_tune_patch.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "IkpcjG6Lvuh_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load existing file\n",
        "df = pd.read_csv(\"fine_tune_patch.csv\")\n",
        "\n",
        "# ‚úÖ Add a new agriculture row\n",
        "new_row = {\n",
        "    \"Text\": \"My wheat crops are drying up even though the soil is moist‚Äîcould it be a fungus or something else?\",\n",
        "    \"label\": 1\n",
        "}\n",
        "df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "# üîÅ Add more rows like this if you want\n",
        "more_rows = [\n",
        "    {\"Text\": \"Water scarcity is severely affecting my maize production this season.\", \"label\": 1},\n",
        "    {\"Text\": \"What fertilizers are best for increasing rice yield in loamy soil?\", \"label\": 1}\n",
        "]\n",
        "df = pd.concat([df, pd.DataFrame(more_rows)], ignore_index=True)\n",
        "\n",
        "# Save back to CSV\n",
        "df.to_csv(\"fine_tune_patch.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "RvUdh7uGy-SI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fine_tune_patch.csv\", \"a\") as f:\n",
        "    f.write(\"\"\"My tomato plants have yellowing leaves despite regular watering,1\n",
        "What's the best organic pesticide for controlling aphids in okra?,1\n",
        "Is it okay to plant sugarcane during the pre-monsoon showers?,1\n",
        "How can I improve soil fertility in fields that were overused with urea?,1\n",
        "My papaya plants are showing signs of leaf curl disease,1\n",
        "What‚Äôs the ideal spacing for planting brinjal seedlings?,1\n",
        "Why is my banana crop not flowering even after applying potash?,1\n",
        "Can I grow groundnuts in sandy loam soil?,1\n",
        "Looking for high-yielding hybrid paddy varieties for my next sowing season,1\n",
        "How to control stem borer in paddy using integrated pest management?,1\n",
        "What is the optimal temperature range for wheat germination?,1\n",
        "My guava tree is dropping fruit prematurely‚Äîwhat could be the reason?,1\n",
        "Which crops can I interplant with maize to boost yield?,1\n",
        "Facing powdery mildew in my cucumber crop‚Äîneed a remedy,1\n",
        "Can excessive irrigation affect flowering in cotton plants?,1\n",
        "I‚Äôm testing vermicompost this season‚Äîwhat should I monitor?,1\n",
        "Best practices for transplanting rice seedlings manually?,1\n",
        "Why are my chili plants showing curled leaves and stunted growth?,1\n",
        "Should I rotate pulses after harvesting mustard?,1\n",
        "Using bio-fertilizers for the first time in paddy‚Äîany tips?,1\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "rVRRZrlGWSLf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load model & tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint_path)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEguMxRaZQh",
        "outputId": "6f1382fa-8960-48dd-ac3e-64f1e9d842d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your correction dataset\n",
        "df = pd.read_csv(\"fine_tune_patch.csv\")\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "# Tokenize\n",
        "encodings = tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "dataset = CustomDataset(encodings, labels)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "fpskCYjKaexf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm  # ‚úÖ Progress bar\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"üöÄ Epoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")\n",
        "\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"‚úÖ Epoch {epoch+1} completed.\\n\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(f\"{checkpoint_path}-fine-tuned\")\n",
        "tokenizer.save_pretrained(f\"{checkpoint_path}-fine-tuned\")\n",
        "print(\"‚úÖ Model saved after fine-tuning.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V71S9MX2alVX",
        "outputId": "b380d443-c513-4818-f2cb-c9e97fb4aef7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:03<00:00, 11.07batch/s, loss=0.000253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 1 completed.\n",
            "\n",
            "üöÄ Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:02<00:00, 12.32batch/s, loss=0.000198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 2 completed.\n",
            "\n",
            "üöÄ Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 36/36 [00:02<00:00, 13.00batch/s, loss=6.06e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 3 completed.\n",
            "\n",
            "‚úÖ Model saved after fine-tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"Today I have a meeting with prime minister\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTm0BVgE6hc",
        "outputId": "b94606bb-7ccf-4734-b2f5-b143bcd279c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Non-agriculture', 0.6770172119140625)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"agri_classification_dataset.csv\")  # Replace with your actual filename\n"
      ],
      "metadata": {
        "id": "Nz1bIMTM3pH9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['text'].tolist(), df['label'].tolist(), test_size=0.9, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4a4-YDWq3-If"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Tokenize each text one by one with tqdm\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in tqdm(test_texts, desc=\"üîÑ Tokenizing test set\"):\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids.append(encoded['input_ids'][0])\n",
        "    attention_masks.append(encoded['attention_mask'][0])\n",
        "\n",
        "# Now stack them\n",
        "import torch\n",
        "test_encodings = {\n",
        "    'input_ids': torch.stack(input_ids),\n",
        "    'attention_mask': torch.stack(attention_masks)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AAO0uoW4C3F",
        "outputId": "c2ed57be-023a-4df3-b193-98fdfa2b0db5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîÑ Tokenizing test set: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90000/90000 [04:01<00:00, 372.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class AgriDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "test_dataset = AgriDataset(test_encodings, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)  # Use larger batch size for faster inference\n"
      ],
      "metadata": {
        "id": "_-ZzCnU24H9l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop = tqdm(test_loader, desc=\"üîç Evaluating\", unit=\"batch\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# üìä Classification report\n",
        "print(\"üìä Classification Report on 90K test data:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Non-agriculture\", \"Agriculture\"]))\n",
        "\n",
        "# üéØ F1-score\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "print(f\"üéØ F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHUAuT4c4MYD",
        "outputId": "8777f2eb-6cfc-46ec-e885-a127e3e708dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "üîç Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5625/5625 [43:38<00:00,  2.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Classification Report on 90K test data:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Non-agriculture       1.00      1.00      1.00     45046\n",
            "    Agriculture       1.00      1.00      1.00     44954\n",
            "\n",
            "       accuracy                           1.00     90000\n",
            "      macro avg       1.00      1.00      1.00     90000\n",
            "   weighted avg       1.00      1.00      1.00     90000\n",
            "\n",
            "üéØ F1 Score: 0.9997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Function to predict label\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        label = \"Agriculture\" if pred == 1 else \"Non-agriculture\"\n",
        "        confidence = probs[0][pred].item()\n",
        "        return f\"{label} ({confidence*100:.2f}%)\"\n",
        "\n",
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=4, placeholder=\"Enter your text here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"üåæ Agriculture Detector\",\n",
        "    description=\"Paste your text below and find out whether it's agriculture-related or not.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "VDk-W3P6DUzt",
        "outputId": "3e354c46-65d1-4750-fda7-16dd035861cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e4f61fd4b2f319a650.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e4f61fd4b2f319a650.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}