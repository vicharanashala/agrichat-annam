{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78b8d782d9be407382d0cebc8b9e92bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f22f4bcb5424253aae45a9dfb10d7b1",
              "IPY_MODEL_d1cef0c240c142edba7792e49140b854",
              "IPY_MODEL_68767fae52f042c6884628e4585a0e01"
            ],
            "layout": "IPY_MODEL_3cb53a26e4e7415aae70728e4314e890"
          }
        },
        "1f22f4bcb5424253aae45a9dfb10d7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3071ed21ba2a40a5b81280efb95e6438",
            "placeholder": "​",
            "style": "IPY_MODEL_42806e25f90d4d90ac1803e51d6a2dc7",
            "value": "  0%"
          }
        },
        "d1cef0c240c142edba7792e49140b854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc04fa63b364128b635d08fb109f771",
            "max": 11250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b228871c6b84d17922978c9aeb0607e",
            "value": 0
          }
        },
        "68767fae52f042c6884628e4585a0e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b41e388a434ef89a9f1f765e3ef735",
            "placeholder": "​",
            "style": "IPY_MODEL_427b071df41b44ca9d6b055e66816cd2",
            "value": " 0/11250 [00:00&lt;?, ?it/s]"
          }
        },
        "3cb53a26e4e7415aae70728e4314e890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3071ed21ba2a40a5b81280efb95e6438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42806e25f90d4d90ac1803e51d6a2dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc04fa63b364128b635d08fb109f771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b228871c6b84d17922978c9aeb0607e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1b41e388a434ef89a9f1f765e3ef735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427b071df41b44ca9d6b055e66816cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c1aA-BKRAgZ",
        "outputId": "13e5e7dc-5c34-450c-e6df-d67aca0ae067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#SAVE_PATH = \"/content/drive/MyDrive/imdb-bert2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "!pip install transformers datasets scikit-learn pandas tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIrufeIORIL_",
        "outputId": "db886741-a926-4038-a9df-6ec1228b9744"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Check GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGtOxGB3Rdth",
        "outputId": "788a4b4b-7ea8-4e3b-d1b2-3ab2d794a40f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Load Dataset\n",
        "df = pd.read_csv(\"agri_classification_dataset.csv\")\n",
        "#df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n"
      ],
      "metadata": {
        "id": "W8Lar47wRgJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['text'].tolist(), df['label'].tolist(), test_size=0.1, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "lA3AxIsKRi2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "s1AUqd9LR0N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Tokenize (save if not already saved)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "if not os.path.exists(SAVE_PATH):\n",
        "    os.makedirs(SAVE_PATH)\n",
        "\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
        "torch.save(train_encodings, f\"{SAVE_PATH}/train_encodings.pt\")\n",
        "torch.save(val_encodings, f\"{SAVE_PATH}/val_encodings.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AHzyO_ReRlRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Dataset Class\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
        "val_dataset = IMDBDataset(val_encodings, val_labels)\n"
      ],
      "metadata": {
        "id": "CnyVCCLaR4ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Model & Training Setup\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylvKuGe_SB0f",
        "outputId": "06b0aca9-2cf4-47d7-da70-bc13660e59f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from transformers import get_scheduler\n",
        "\n",
        "\n",
        "\n",
        "# ✅ Add Scheduler\n",
        "num_epochs = 5\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=100,\n",
        "    num_training_steps=num_training_steps,\n",
        ")\n",
        "\n",
        "# ✅ Training loop with scheduler\n",
        "for epoch in range(num_epochs):\n",
        "    try:\n",
        "        model.train()\n",
        "        print(f\"🔁 Epoch {epoch + 1}/{num_epochs}\")\n",
        "        loop = tqdm(train_loader)\n",
        "        for batch in loop:\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()  # ✅ Step the scheduler\n",
        "            loop.set_description(f\"Epoch {epoch + 1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # ✅ Save after each epoch\n",
        "        model.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}\")\n",
        "        tokenizer.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}\")\n",
        "        print(f\"✅ Model saved after epoch {epoch+1}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error occurred, saving current checkpoint...\")\n",
        "        model.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}-crash\")\n",
        "        tokenizer.save_pretrained(f\"{SAVE_PATH}/checkpoint-epoch{epoch+1}-crash\")\n",
        "        raise e\n",
        "\n",
        "# ✅ Evaluation after training\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(val_loader, desc=\"🔍 Evaluating\"):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, axis=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"\\n📊 Classification Report on Validation Set:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Non-agriculture\", \"Agriculture\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "78b8d782d9be407382d0cebc8b9e92bc",
            "1f22f4bcb5424253aae45a9dfb10d7b1",
            "d1cef0c240c142edba7792e49140b854",
            "68767fae52f042c6884628e4585a0e01",
            "3cb53a26e4e7415aae70728e4314e890",
            "3071ed21ba2a40a5b81280efb95e6438",
            "42806e25f90d4d90ac1803e51d6a2dc7",
            "3bc04fa63b364128b635d08fb109f771",
            "0b228871c6b84d17922978c9aeb0607e",
            "c1b41e388a434ef89a9f1f765e3ef735",
            "427b071df41b44ca9d6b055e66816cd2"
          ]
        },
        "id": "hlcQwiqySFWh",
        "outputId": "2a919796-91a0-498a-e9cf-989e939088f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Epoch 1/5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11250 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b8d782d9be407382d0cebc8b9e92bc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Change this to your desired checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/imdb-bert1/checkpoint-epoch3-fine-tuned-fine-tuned\"\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint_path)\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "model.eval()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIfuRrZYSJcE",
        "outputId": "9d98c035-0307-4c4e-a385-9d5dd6e27c93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        label = \"Agriculture\" if pred == 1 else \"Non-agriculture\"\n",
        "        confidence = probs[0][pred].item()\n",
        "\n",
        "    return label, confidence\n"
      ],
      "metadata": {
        "id": "1B6fsgyMnLnS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    \"My wheat crops are drying up even though the soil is moist—could it be a fungus or something else?\",\n",
        "    \"The recent Bollywood film touched upon farmer suicides, quite a heavy topic.\",\n",
        "    \"How do I switch from chemical to organic farming without losing my yield?\",\n",
        "    \"Do you know the actor who played the farmer in that Marathi biopic?\",\n",
        "    \"Water stress in maize during tasseling stage is affecting cob formation—any recommendations?\",\n",
        "    \"Just watched a documentary on climate change and its effects on agriculture in the Himalayan belt.\",\n",
        "    \"I heard neem-based pesticides are good, but I don’t know the dilution ratio for chili crops.\",\n",
        "    \"Can excessive rainfall delay flowering in pulses like urad and moong?\",\n",
        "    \"My neighbors used some new fertigation technique; is that viable for sugarcane in clay soil?\",\n",
        "    \"The storyline was confusing, but the cinematography in the paddy fields looked stunning!\",\n",
        "    ]\n",
        "\n",
        "for text in examples:\n",
        "    label, conf = predict_sentiment(text)\n",
        "    print(f\"📝 Review: {text}\\n🔎 Prediction: {label} ({conf*100:.2f}% confidence)\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XwtmI9dnRxQ",
        "outputId": "8e5da42c-84c3-4da3-ad4a-64ccb90cc23b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Review: My wheat crops are drying up even though the soil is moist—could it be a fungus or something else?\n",
            "🔎 Prediction: Agriculture (98.36% confidence)\n",
            "\n",
            "📝 Review: The recent Bollywood film touched upon farmer suicides, quite a heavy topic.\n",
            "🔎 Prediction: Non-agriculture (99.78% confidence)\n",
            "\n",
            "📝 Review: How do I switch from chemical to organic farming without losing my yield?\n",
            "🔎 Prediction: Agriculture (98.80% confidence)\n",
            "\n",
            "📝 Review: Do you know the actor who played the farmer in that Marathi biopic?\n",
            "🔎 Prediction: Non-agriculture (95.95% confidence)\n",
            "\n",
            "📝 Review: Water stress in maize during tasseling stage is affecting cob formation—any recommendations?\n",
            "🔎 Prediction: Agriculture (99.69% confidence)\n",
            "\n",
            "📝 Review: Just watched a documentary on climate change and its effects on agriculture in the Himalayan belt.\n",
            "🔎 Prediction: Non-agriculture (91.25% confidence)\n",
            "\n",
            "📝 Review: I heard neem-based pesticides are good, but I don’t know the dilution ratio for chili crops.\n",
            "🔎 Prediction: Agriculture (99.46% confidence)\n",
            "\n",
            "📝 Review: Can excessive rainfall delay flowering in pulses like urad and moong?\n",
            "🔎 Prediction: Agriculture (99.62% confidence)\n",
            "\n",
            "📝 Review: My neighbors used some new fertigation technique; is that viable for sugarcane in clay soil?\n",
            "🔎 Prediction: Agriculture (99.35% confidence)\n",
            "\n",
            "📝 Review: The storyline was confusing, but the cinematography in the paddy fields looked stunning!\n",
            "🔎 Prediction: Non-agriculture (99.92% confidence)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment( \"My wheat crops are drying up even though the soil is moist—could it be a fungus or something else?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtcdV7tMcxyZ",
        "outputId": "68c28077-c38f-4a05-9ba5-92a4a2ba5283"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Agriculture', 0.9883082509040833)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-_sPM5RVYb_",
        "outputId": "ceeaa401-87eb-4677-9dfc-ae456074fff3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3  Unnamed: 4     Unnamed: 5  \\\n",
            "0         NaN       Year      Month        Day       State       District   \n",
            "1         NaN       2025       June         23  Tamil Nadu  Ramanthapuram   \n",
            "2         NaN       2025       June         23  Tamil Nadu  Ramanthapuram   \n",
            "\n",
            "    Unnamed: 6 Unnamed: 7 Unnamed: 8  Unnamed: 9  \\\n",
            "0       Sector     Season       Crop  Sl No. - Q   \n",
            "1  Agriculture     Kharif     Chilli          Q1   \n",
            "2  Agriculture     Kharif     Chilli          Q2   \n",
            "\n",
            "                                         Unnamed: 10 Unnamed: 11  \\\n",
            "0                                           Question  Sl No. - A   \n",
            "1  How much FYM-Farm yard manure should I add to ...          A1   \n",
            "2  What are the market opportunities I have if I ...          A2   \n",
            "\n",
            "                                         Unnamed: 12  \n",
            "0                                             Answer  \n",
            "1  Apply 8–10 tons per acre of well-decomposed FY...  \n",
            "2  Chillies have market opportunities in food pro...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm  # ✅ Import tqdm\n",
        "\n",
        "# 🔽 Load your CSV file\n",
        "df = pd.read_csv(\"twitter_dataset.csv\")  # Replace with actual file path\n",
        "\n",
        "# 🔽 Run prediction on the 'Text' column\n",
        "agri_count = 0\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "# ✅ tqdm for progress bar\n",
        "for question in tqdm(df['Text'], desc=\"🔍 Predicting\", unit=\"question\"):\n",
        "    label, conf = predict_sentiment(question)\n",
        "    predictions.append(label)\n",
        "    confidences.append(conf)\n",
        "    if label == \"Agriculture\":\n",
        "        agri_count += 1\n",
        "\n",
        "# 🔽 Add to DataFrame\n",
        "df['predicted_label'] = predictions\n",
        "df['confidence'] = confidences\n",
        "\n",
        "# 🔽 Print the count\n",
        "print(f\"🌾 Total Agriculture-related questions: {agri_count} out of {len(df)}\")\n",
        "\n",
        "# 🔽 Save results\n",
        "df.to_csv(\"questions_with_predictions.csv\", index=False)\n",
        "print(\"✅ Saved predictions to questions_with_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HAuUss5Uyub",
        "outputId": "d05f656d-43cd-46cb-eb2d-7642afdd3706"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Predicting: 100%|██████████| 10000/10000 [01:51<00:00, 89.40question/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌾 Total Agriculture-related questions: 0 out of 10000\n",
            "✅ Saved predictions to questions_with_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm  # ✅ Import tqdm\n",
        "\n",
        "# 🔽 Load your CSV file\n",
        "df = pd.read_csv(\"Copy of Tamilnadu Crops by Ponugoti Kavya_Chilli-Tamil Nadu.csv\")  # Replace with actual file path\n",
        "\n",
        "# 🔽 Run prediction on the 'Text' column\n",
        "agri_count = 0\n",
        "predictions = []\n",
        "confidences = []\n",
        "\n",
        "# ✅ tqdm for progress bar\n",
        "for question in tqdm(df['Unnamed: 10'], desc=\"🔍 Predicting\", unit=\"question\"):\n",
        "    label, conf = predict_sentiment(question)\n",
        "    predictions.append(label)\n",
        "    confidences.append(conf)\n",
        "    if label == \"Agriculture\":\n",
        "        agri_count += 1\n",
        "\n",
        "# 🔽 Add to DataFrame\n",
        "df['predicted_label'] = predictions\n",
        "df['confidence'] = confidences\n",
        "\n",
        "# 🔽 Print the count\n",
        "print(f\"🌾 Total Agriculture-related questions: {agri_count} out of {len(df)}\")\n",
        "\n",
        "# 🔽 Save results\n",
        "df.to_csv(\"questions_with_predictions.csv\", index=False)\n",
        "print(\"✅ Saved predictions to questions_with_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rPG07Y117N1",
        "outputId": "f04199cf-47e8-4c9b-fe9d-c64ef6831a6b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Predicting: 100%|██████████| 202/202 [00:02<00:00, 100.58question/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌾 Total Agriculture-related questions: 202 out of 202\n",
            "✅ Saved predictions to questions_with_predictions.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agri_df = df[df['predicted_label'] == \"Agriculture\"]\n",
        "agri_df['label'] = 0\n",
        "agri_df[['Text', 'label']].to_csv(\"fine_tune_patch.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "IkpcjG6Lvuh_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load existing file\n",
        "df = pd.read_csv(\"fine_tune_patch.csv\")\n",
        "\n",
        "# ✅ Add a new agriculture row\n",
        "new_row = {\n",
        "    \"Text\": \"My wheat crops are drying up even though the soil is moist—could it be a fungus or something else?\",\n",
        "    \"label\": 1\n",
        "}\n",
        "df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "\n",
        "# 🔁 Add more rows like this if you want\n",
        "more_rows = [\n",
        "    {\"Text\": \"Water scarcity is severely affecting my maize production this season.\", \"label\": 1},\n",
        "    {\"Text\": \"What fertilizers are best for increasing rice yield in loamy soil?\", \"label\": 1}\n",
        "]\n",
        "df = pd.concat([df, pd.DataFrame(more_rows)], ignore_index=True)\n",
        "\n",
        "# Save back to CSV\n",
        "df.to_csv(\"fine_tune_patch.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "RvUdh7uGy-SI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"fine_tune_patch.csv\", \"a\") as f:\n",
        "    f.write(\"\"\"My tomato plants have yellowing leaves despite regular watering,1\n",
        "What's the best organic pesticide for controlling aphids in okra?,1\n",
        "Is it okay to plant sugarcane during the pre-monsoon showers?,1\n",
        "How can I improve soil fertility in fields that were overused with urea?,1\n",
        "My papaya plants are showing signs of leaf curl disease,1\n",
        "What’s the ideal spacing for planting brinjal seedlings?,1\n",
        "Why is my banana crop not flowering even after applying potash?,1\n",
        "Can I grow groundnuts in sandy loam soil?,1\n",
        "Looking for high-yielding hybrid paddy varieties for my next sowing season,1\n",
        "How to control stem borer in paddy using integrated pest management?,1\n",
        "What is the optimal temperature range for wheat germination?,1\n",
        "My guava tree is dropping fruit prematurely—what could be the reason?,1\n",
        "Which crops can I interplant with maize to boost yield?,1\n",
        "Facing powdery mildew in my cucumber crop—need a remedy,1\n",
        "Can excessive irrigation affect flowering in cotton plants?,1\n",
        "I’m testing vermicompost this season—what should I monitor?,1\n",
        "Best practices for transplanting rice seedlings manually?,1\n",
        "Why are my chili plants showing curled leaves and stunted growth?,1\n",
        "Should I rotate pulses after harvesting mustard?,1\n",
        "Using bio-fertilizers for the first time in paddy—any tips?,1\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "rVRRZrlGWSLf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load model & tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(checkpoint_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(checkpoint_path)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiEguMxRaZQh",
        "outputId": "6f1382fa-8960-48dd-ac3e-64f1e9d842d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your correction dataset\n",
        "df = pd.read_csv(\"fine_tune_patch.csv\")\n",
        "texts = df['Text'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "# Tokenize\n",
        "encodings = tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "dataset = CustomDataset(encodings, labels)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
      ],
      "metadata": {
        "id": "fpskCYjKaexf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm  # ✅ Progress bar\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"🚀 Epoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")\n",
        "\n",
        "    for batch in loop:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    print(f\"✅ Epoch {epoch+1} completed.\\n\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(f\"{checkpoint_path}-fine-tuned\")\n",
        "tokenizer.save_pretrained(f\"{checkpoint_path}-fine-tuned\")\n",
        "print(\"✅ Model saved after fine-tuning.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V71S9MX2alVX",
        "outputId": "b380d443-c513-4818-f2cb-c9e97fb4aef7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 36/36 [00:03<00:00, 11.07batch/s, loss=0.000253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 1 completed.\n",
            "\n",
            "🚀 Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 36/36 [00:02<00:00, 12.32batch/s, loss=0.000198]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 2 completed.\n",
            "\n",
            "🚀 Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 36/36 [00:02<00:00, 13.00batch/s, loss=6.06e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 3 completed.\n",
            "\n",
            "✅ Model saved after fine-tuning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_sentiment(\"Today I have a meeting with prime minister\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTm0BVgE6hc",
        "outputId": "b94606bb-7ccf-4734-b2f5-b143bcd279c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Non-agriculture', 0.6770172119140625)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"agri_classification_dataset.csv\")  # Replace with your actual filename\n"
      ],
      "metadata": {
        "id": "Nz1bIMTM3pH9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df['text'].tolist(), df['label'].tolist(), test_size=0.9, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4a4-YDWq3-If"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Tokenize each text one by one with tqdm\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for text in tqdm(test_texts, desc=\"🔄 Tokenizing test set\"):\n",
        "    encoded = tokenizer.encode_plus(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=512,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids.append(encoded['input_ids'][0])\n",
        "    attention_masks.append(encoded['attention_mask'][0])\n",
        "\n",
        "# Now stack them\n",
        "import torch\n",
        "test_encodings = {\n",
        "    'input_ids': torch.stack(input_ids),\n",
        "    'attention_mask': torch.stack(attention_masks)\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AAO0uoW4C3F",
        "outputId": "c2ed57be-023a-4df3-b193-98fdfa2b0db5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔄 Tokenizing test set: 100%|██████████| 90000/90000 [04:01<00:00, 372.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class AgriDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': torch.tensor(self.encodings['input_ids'][idx]),\n",
        "            'attention_mask': torch.tensor(self.encodings['attention_mask'][idx]),\n",
        "            'labels': torch.tensor(self.labels[idx])\n",
        "        }\n",
        "\n",
        "test_dataset = AgriDataset(test_encodings, test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)  # Use larger batch size for faster inference\n"
      ],
      "metadata": {
        "id": "_-ZzCnU24H9l"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, f1_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    loop = tqdm(test_loader, desc=\"🔍 Evaluating\", unit=\"batch\")\n",
        "    for batch in loop:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# 📊 Classification report\n",
        "print(\"📊 Classification Report on 90K test data:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=[\"Non-agriculture\", \"Agriculture\"]))\n",
        "\n",
        "# 🎯 F1-score\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "print(f\"🎯 F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHUAuT4c4MYD",
        "outputId": "8777f2eb-6cfc-46ec-e885-a127e3e708dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Evaluating: 100%|██████████| 5625/5625 [43:38<00:00,  2.15batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Classification Report on 90K test data:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "Non-agriculture       1.00      1.00      1.00     45046\n",
            "    Agriculture       1.00      1.00      1.00     44954\n",
            "\n",
            "       accuracy                           1.00     90000\n",
            "      macro avg       1.00      1.00      1.00     90000\n",
            "   weighted avg       1.00      1.00      1.00     90000\n",
            "\n",
            "🎯 F1 Score: 0.9997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio --quiet\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Function to predict label\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        pred = torch.argmax(probs, dim=1).item()\n",
        "        label = \"Agriculture\" if pred == 1 else \"Non-agriculture\"\n",
        "        confidence = probs[0][pred].item()\n",
        "        return f\"{label} ({confidence*100:.2f}%)\"\n",
        "\n",
        "# Gradio UI\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Textbox(lines=4, placeholder=\"Enter your text here...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"🌾 Agriculture Detector\",\n",
        "    description=\"Paste your text below and find out whether it's agriculture-related or not.\"\n",
        ")\n",
        "\n",
        "# Launch\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "VDk-W3P6DUzt",
        "outputId": "3e354c46-65d1-4750-fda7-16dd035861cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e4f61fd4b2f319a650.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e4f61fd4b2f319a650.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}